{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Download libraries**"
      ],
      "metadata": {
        "id": "9X-VR6oe3KBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets peft accelerate evaluate"
      ],
      "metadata": {
        "id": "install-libraries"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Inspect Data**"
      ],
      "metadata": {
        "id": "H_HWM2fC52pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "import-libraries"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('path_to_your_file1.csv')  # Replace with actual path\n",
        "df2 = pd.read_csv('path_to_your_file2.csv')  # Replace with actual path\n",
        "df = pd.concat([df1, df2], ignore_index=True)"
      ],
      "metadata": {
        "id": "concat-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1['role'].value_counts())",
        "print(df1['category'].value_counts())",
        "print(df1['difficulty'].value_counts())",
        "print(df['answer'].isnull().sum())"
      ],
      "metadata": {
        "id": "inspect-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "H_HWM2fC52pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r\"<.*?>\", \" \", text)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.\\,\\?\\!]\", \" \", text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "uXHkpt0W56k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_question'] = df['question'].apply(clean_text)"
      ],
      "metadata": {
        "id": "-TSibP1g6Anw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Modification**"
      ],
      "metadata": {
        "id": "TdZEI75Y4GOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = [\"data scientist\" for i in range(df2.shape[0])]\n",
        "df2['role'] = role"
      ],
      "metadata": {
        "id": "GGcAXzNQ4DrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.drop(columns=['difficulty', 'category'], inplace=True)\n",
        "df2.drop(columns='answer', inplace=True)"
      ],
      "metadata": {
        "id": "BYpjY6xs4sQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df1.columns)\n",
        "print(df2.columns)"
      ],
      "metadata": {
        "id": "check-columns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "dataset = Dataset.from_pandas(df[['clean_question', 'answer']])"
      ],
      "metadata": {
        "id": "create-dataset"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
